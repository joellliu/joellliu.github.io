<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jiang Liu</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="images/jhu.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jiang Liu</name>
              </p>
              <p>I am a Senior Applied Research Scientist in the <a href="https://amdgenai.github.io/team/">AMD GenAI team</a>. I received my Ph.D degree from <a href="https://engineering.jhu.edu/ece/">Department of Electrical and Computer Engineering</a>, <a href="https://www.jhu.edu/">Johns Hopkins University</a> in 2024,
                advised by <a href="https://engineering.jhu.edu/ece/faculty/rama-chellappa/">Prof. Rama Chellappa</a>. I was awarded the <a href="https://www.amazon.science/news-and-features/johns-hopkins-and-amazon-announce-four-fellow-and-eight-faculty-research-awards">Amazon AI2AI Fellowship</a> in 2023.
                I received my BSE degree from <a href="https://www.au.tsinghua.edu.cn/">Department of Automation</a>, <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a> in 2019 advised by <a href="http://ivg.au.tsinghua.edu.cn/~jfeng/">Prof. Jianjiang Feng</a>
                and <a href="https://scholar.google.com/citations?user=6a79aPwAAAAJ&hl=en">Prof. Jie Zhou</a>.


              </p>
              <p>
                In summer 2023, I interned at <a href="https://azure.microsoft.com/en-us/solutions/ai"> Microsoft Azure AI </a> with <a href="https://jianfengwang.me/">Dr. Jianfeng Wang</a> working on multi-modal large language models. In summer 2022, I worked as an Applied Scientist Intern at <a href="https://aws.amazon.com/machine-learning/ai-services/"> Amazon AWS AI </a> working on vision-language models mentored by
                <a href="http://www.huiding.org">Dr. Hui Ding</a>,
                <a href="https://zhaoweicai.github.io/">Dr. Zhaowei Cai</a>, and
                <a href="https://www.ytzhang.net/">Dr. Yuting Zhang</a>. I've also worked as a Deep Learning Research Scientist Intern
                at <a href="https://subtlemedical.com/">Subtle Medical</a> developing novel Transformer-based magnetic resonance imaging (MRI) algorithms.

              </p>

              <p style="text-align:center">
                <a href="mailto:jiang.liu@amd.com">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=IbeXR9cAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/jiang-liu-4a2283131/">Linkedin</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jiangliu.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My current research interests include large language models, vision-language models, and trustworthy AI. I lead the development of <a href="https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html">Instella</a>, a series of fully open language models at AMD.
                <p style="color:red;">We are hiring full-time research scientists and research interns in all areas of generative AI. Feel free to drop me an email with your CV if interested. Research collaborations are also welcome!</p>
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
                <li><b>Sep 2025:</b> One paper accepted to <a href="https://neurips.cc/Conferences/2025">NeurIPS 2025</a> as spotlight. Check out <a href="https://videomarathon.github.io/">VideoMarathon</a>.</li>
                <li><b>Aug 2025:</b> Two papers accepted to <a href="https://2025.emnlp.org/">EMNLP 2025</a>. Check out <a href="https://prakamya-mishra.github.io/TTTBench/">TTT-Bench</a> and <a href="https://agentlaboratory.github.io/">Agent Laboratory</a>.</li>
                <li><b>July 2025:</b> Promoted to Senior Applied Research Scientist at AMD.</li>
                <!-- Add more news items as needed -->
              </ul>
            </td>
          </tr>
        </tbody></table>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Works</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        <!-- Selected Publications section (images and abstracts removed) -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://wikichao.github.io/DRIFT/">
                <papertitle> DRIFT: Directional Reasoning Injection for Fine-Tuning MLLMs
                </papertitle>
              </a>
              <br>
              Chao Huang, Zeliang Zhang, <strong>Jiang Liu</strong>, Ximeng Sun, Jialian Wu, Xiaodong Yu, Ze Wang, Chenliang Xu, Emad Barsoum, Zicheng Liu
              <br>
              <em>ArXiv</em>, 2025
              <br>
              <a href="https://wikichao.github.io/DRIFT/">Project Page</a>
            </td>
          </tr>
          
          
          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://xingruiwang.github.io/projects/XModBench/">
                <papertitle> XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models
                </papertitle>
              </a>
              <br>
              Xingrui Wang , <strong>Jiang Liu</strong> , Chao Huang , Xiaodong Yu , Ze Wang , Ximeng Sun , Jialian Wu , Alan Yuille , Emad Barsoum , Zicheng Liu
              <br>
              <em>ArXiv</em>, 2025
              <br>
              <a href="https://xingruiwang.github.io/projects/XModBench/">Project Page</a>
            </td>
          </tr>
          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2510.01010">
                <papertitle> ImageDoctor: Diagnosing Text-to-Image Generation via Grounded Image Reasoning
                </papertitle>
              </a>
              <br>
              Yuxiang Guo*, <strong>Jiang Liu</strong>*, Ze Wang, Hao Chen, Ximeng Sun, Yang Zhao, Jialian Wu, Xiaodong Yu, Zicheng Liu, Emad Barsoum
              <br>
              <em>ArXiv</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2510.01010">arXiv</a> /
              <a href="https://image-doctor.github.io/">Project Page</a>
            </td>
          </tr>
          
          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://www.arxiv.org/abs/2509.24251">
                <papertitle> Latent Visual Reasoning
                </papertitle>
              </a>
              <br>
              Bangzheng Li, Ximeng Sun, <strong>Jiang Liu</strong>, Ze Wang, Jialian Wu, Xiaodong Yu, Hao Chen, Emad Barsoum, Muhao Chen, Zicheng Liu
              <br>
              <em>ArXiv</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2509.24251">arXiv</a>
            </td>
          </tr>

          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
            <td style="padding:20px;width:100%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2509.18521">
                <papertitle> APRIL: Active Partial Rollouts in Reinforcement Learning to Tame Long-tail Generation
                </papertitle>
              </a>
              <br>
              Yuzhen Zhou, Jiajun Li, Yusheng Su, Gowtham Ramesh, Zilin Zhu, Xiang Long, Chenyang Zhao, Jin Pan, Xiaodong Yu, Ze Wang, Kangrui Du, Jialian Wu, Ximeng Sun, <strong>Jiang Liu</strong>, Qiaolin Yu, Hao Chen, Zicheng Liu, Emad Barsoum
              <br>
              <em>ArXiv</em>, 2025
              <br>
              <a href="https://arxiv.org/abs/2509.18521">arXiv</a> /
              <a href="https://github.com/RLsys-Foundation/APRIL">Code</a> 
            </td>
          </tr>

          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://prakamya-mishra.github.io/TTTBench/">
              <papertitle> TTT-Bench: A Benchmark for Evaluating Reasoning Ability with Simple and Novel Tic-Tac-Toe-style Games
              </papertitle>
            </a>
            <br>
            Prakamya Mishra, <strong>Jiang Liu</strong>, Jialian Wu, Xiaodong Yu, Zicheng Liu, Emad Barsoum
            <br>
            <em>EMNLP Main Conference</em>, 2025
            <br>
            <a href="https://prakamya-mishra.github.io/TTTBench/">Project Page</a> /
            <a href="https://arxiv.org/abs/2506.10209">arXiv</a> /
            <a href="https://huggingface.co/datasets/amd/TTT-Bench">Data</a> 
          </td>
        </tr>

          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://agentlaboratory.github.io/">
              <papertitle> Agent Laboratory: Using LLM Agents as Research Assistants
              </papertitle>
            </a>
            <br>
            Samuel Schmidgall, Yusheng Su, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, <strong>Jiang Liu</strong>, Michael Moor, Zicheng Liu, and Emad Barsoum
            <br>
            <em>EMNLP Findings</em>, 2025
            <br>
            <a href="https://agentlaboratory.github.io/">Project Page</a> /
            <a href="https://arxiv.org/pdf/2501.04227">arXiv</a> /
            <a href="https://github.com/SamuelSchmidgall/AgentLaboratory">code</a> /
            <a href="bibs/agentlab.bib">bibtex</a>
          </td>
        </tr>

                                    <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-t2i/README.html">
                  <papertitle>Instella-T2I: Pushing the Limits of 1D Discrete
Latent Space Image Generation</papertitle>
                </a>
                <br>
                Ze Wang, Hao Chen, Benran Hu, <strong>Jiang Liu</strong>, Ximeng Sun, Jialian Wu, Yusheng Su, Xiaodong Yu, Emad
Barsoum, Zicheng Liu
                <br>
                <em>Tech Report</em>, 2025
                <br>
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-t2i/README.html">Blog</a> /
                <a href="https://github.com/AMD-AIG-AIMA/Instella-T2I">Code</a> /
                <a href="https://arxiv.org/pdf/2506.21022">arXiv</a> /
                <a href="https://huggingface.co/amd/Instella-T2I">Huggingface</a>
              </td>
            </tr> 

                            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-math-language/README.html">
                  <papertitle>Instella-Math: A Fully Open Language Model with Reasoning Capability</papertitle>
                </a>
                <br>
                Xiaodong Yu, <strong>Jiang Liu</strong>, Yusheng Su, Gowtham Ramesh, Zicheng Liu et al.
                <br>
                <em>Tech Report</em>, 2025
                <br>
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-math-language/README.html">Blog</a> /
                <a href="https://github.com/AMD-AIG-AIMA/Instella-Math">Code</a> /
                <a href="https://huggingface.co/amd/Instella-3B-Math">Huggingface</a>
              </td>
            </tr> 
        
                    <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-long-context/README.html">
                  <papertitle>Instella-Long: A Fully Open Language Model with Long-Context Capability</papertitle>
                </a>
                <br>
                Jialian Wu, <strong>Jiang Liu</strong>, Sudhanshu Ranjan, Xiaodong Yu, Gowtham Ramesh, Prakamya Mishra, Zicheng Liu, et al.
                <br>
                <em>Tech Report</em>, 2025
                <br>
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/instella-long-context/README.html">Blog</a> /
                <a href="https://github.com/AMD-AIG-AIMA/Instella/tree/instella-long">Code</a> /
                <a href="https://huggingface.co/amd/Instella-3B-Long-Instruct">Huggingface</a>
              </td>
            </tr> 
            
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html">
                  <papertitle>Instella: New State-of-the-art Fully Open 3B Language Models</papertitle>
                </a>
                <br>
                <strong>Jiang Liu</strong>, Jialian Wu, Xiaodong Yu, Prakamya Mishra, Sudhanshu Ranjan, Zicheng Liu, et al.
                <br>
                <em>Tech Report</em>, 2025
                <br>
                <a href="https://rocm.blogs.amd.com/artificial-intelligence/introducing-instella-3B/README.html">Blog</a> /
                <a href="https://github.com/AMD-AIG-AIMA/Instella">Code</a> /
                <a href="https://huggingface.co/collections/amd/instella-67c8a2c56e9198c85a97dd08">Huggingface</a>
              </td>
            </tr> 

                <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://videomarathon.github.io/">
              <papertitle>Unleashing Hour-Scale Video Training for Long Video-Language Understanding</papertitle>
            </a>
            <br>
            Jingyang Lin, Jialian Wu, Ximeng Sun, Ze Wang, <strong>Jiang Liu</strong>, Yusheng Su, Xiaodong Yu, Hao Chen, Jiebo Luo, Zicheng Liu, Emad Barsoum
            <br>
            <em>NeurIPS</em>, 2025 (Spotlight)
            <br>
            <a href="https://videomarathon.github.io/">Project Page</a> /
            <a href="https://arxiv.org/pdf/2506.05332">arXiv</a> /
            <a href="https://github.com/jylins/hourllava">code</a> /
            <a href="https://huggingface.co/datasets/jylins/videomarathon">dataset</a>
          </td>
        </tr>

                <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2311.09753">
              <papertitle>DIFFNAT: Improving Diffusion Image Quality Using Natural Image Statistics</papertitle>
            </a>
            <br>
            Aniket Roy, Maiterya Suin, Anshul Shah, Ketul Shah, <strong>Jiang Liu</strong>, Rama Chellappa
            <br>
            <em>TMLR</em>, 2025
            <br>
            <a href="https://arxiv.org/pdf/2311.09753">arXiv</a>
          </td>
        </tr>

        <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2504.09656">
              <papertitle>MOVi: Training-free Text-conditioned Multi-Object Video Generation</papertitle>
            </a>
            <br>
            Aimon Rahman, <strong>Jiang Liu</strong>, Ze Wang, Ximeng Sun, Jialian Wu, Xiaodong Yu, Yusheng Su, Vishal M. Patel, Zicheng Liu, Emad Barsoum
            <br>
            <em>arXiv</em>, 2025
            <br>
            <a href="https://arxiv.org/pdf/2505.22980">arXiv</a> /
            <a href="https://github.com/aimansnigdha/MOVi">code</a>
          </td>
        </tr>

                <tr>
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://xingruiwang.github.io/projects/KeyVID/">
              <papertitle>KeyVID: Keyframe-Aware Video Diffusion for Audio-Synchronized Visual Animation</papertitle>
            </a>
            <br>
            Xingrui Wang, <strong>Jiang Liu</strong>, Ze Wang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Yusheng Su, Alan Yuille, Zicheng Liu, Emad Barsoum
            <br>
            <em>ICCV Workshop Gen4AVC</em>, 2025
            <br>
            <a href="https://xingruiwang.github.io/projects/KeyVID/">Project Page</a> /
            <a href="https://arxiv.org/pdf/2504.09656">arXiv</a> /
            <a href="https://github.com/XingruiWang/KeyVID">code</a>
          </td>
        </tr>
        
                <tr>
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2502.15920">
              <papertitle>Self-Taught Agentic Long Context Understanding</papertitle>
            </a>
            <br>
            Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, <strong>Jiang Liu</strong>, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum
            <br>
            <em>ACL</em>, 2025
            <br>
            <a href="https://arxiv.org/pdf/2502.15920">PDF</a> /
            <a href="https://github.com/EvanZhuang/AgenticLU">code</a>
          </td>
        </tr>

                        <tr>
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SoftVQ-VAE_Efficient_1-Dimensional_Continuous_Tokenizer_CVPR_2025_paper.pdf">
              <papertitle>SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer</papertitle>
            </a>
            <br>
            Hao Chen, Ze Wang, Xiang Li, Ximeng Sun, Fangyi Chen, <strong>Jiang Liu</strong>,
            Jindong Wang, Bhiksha Raj, Zicheng Liu, Emad Barsoum
            <br>
            <em>CVPR</em>, 2025
            <br>
            <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Chen_SoftVQ-VAE_Efficient_1-Dimensional_Continuous_Tokenizer_CVPR_2025_paper.pdf">PDF</a> /
            <a href="https://github.com/Hhhhhhao/continuous_tokenizer">code</a>
          </td>
        </tr>

        
                                    <tr>
              <td style="padding:20px;width=100%;vertical-align:middle">
                <a href="https://www.amd.com/en/developer/resources/technical-articles/introducing-the-first-amd-1b-language-model.html">
                  <papertitle>AMD OLMo: Introducing the First AMD 1B Language Models</papertitle>
                </a>
                <br>
                <strong>Jiang Liu</strong>, Jialian Wu, Prakamya Mishra, Zicheng Liu et al.
                <br>
                <em>Tech Report</em>, 2025
                <br>
                <a href="https://www.amd.com/en/developer/resources/technical-articles/introducing-the-first-amd-1b-language-model.html">Blog</a> /
                <a href="https://huggingface.co/amd/AMD-OLMo">Huggingface</a>
              </td>
            </tr> 


          <tr onmouseout="i2a_stop()" onmouseover="i2a_start()">
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2311.15551">
              <papertitle> Instruct2Attack: Language-Guided Semantic Adversarial Attacks
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu</strong>,
            Chen Wei, Yuxiang Guo, Heng Yu, Alan Yuille, Soheil Feizi, Chun Pong Lau, Rama Chellappa
            <br>
            <em>Under Submission</em>, 2024
            <br>
            <a href="https://arxiv.org/abs/2311.15551">arXiv</a> /
            <a href="bibs/liu_2023_i2a.bib">bibtex</a>
          </td>
        </tr>

        <tr onmouseout="dp_stop()" onmouseover="dp_start()">
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2305.13625">
              <papertitle> DiffProtect: Generate Adversarial Examples with Diffusion Models for Facial Privacy Protection
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu</strong>,
            Chun Pong Lau, Yuxiang Guo, Zhaoyang Wang, Rama Chellappa
            <br>
            <em>Under Submission</em>, 2023
            <br>
            <a href="https://arxiv.org/abs/2305.13625">arXiv</a> /
            <a href="bibs/liu_2023_diffprotect.bib">bibtex</a> /
            <a href="https://github.com/joellliu/DiffProtect">code</a>
          </td>
        </tr>

        <tr onmouseout="ijsat_stop()" onmouseover="ijsat_start()">
          <td style="padding:20px;width:100%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/abstract/document/10155464">
              <papertitle> Interpolated Joint Space Adversarial Training for Robust and Generalizable Defenses
              </papertitle>
            </a>
            <br>
            Chun Pong Lau,
            <strong>Jiang Liu</strong>,
            Hossein Souri, Wei-An Lin, Soheil Feizi, Rama Chellappa
            <br>
            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/abstract/document/10155464">IEEE</a> /
            <a href="https://arxiv.org/abs/2112.06323">arXiv</a> /
            <a href="bibs/lau_2021_ijsat.bib">bibtex</a>
          </td>
        </tr>

        <tr onmouseout="mmt_stop()" onmouseover="mmt_start()">
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2204.13738">
              <papertitle> One Model to Synthesize Them All: Multi-contrast Multi-scale Transformer for Missing Data Imputation
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu*</strong>,
            Srivathsa Pasumarthi*, Ben Duffy, Enhao Gong, Keshav Datta, Greg Zaharchuk (*equal contribution)
            <br>
            <em>IEEE Transactions on Medical Imaging (TMI)</em>, 2023
            <br>
            <a href="https://ieeexplore.ieee.org/document/10081095">IEEE</a> /
            <a href="https://arxiv.org/abs/2204.13738">arXiv</a> /
            <a href="bibs/Liu_2023_one.bib">bibtex</a>
          </td>
        </tr>

        <tr onmouseout="poly_stop()" onmouseover="poly_start()">
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://arxiv.org/abs/2302.07387">
              <papertitle> PolyFormer: Referring Image Segmentation as Sequential Polygon Generation
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu*</strong>, Hui Ding*, Zhaowei Cai, Yuting Zhang, Ravi Kumar Satzoda, Vijay Mahadevan, R. Manmatha (*equal contribution)
            <br>
            <em>CVPR</em>, 2023
            <br>
            <a href="https://polyformer.github.io/">Project Page</a> /
            <a href="https://arxiv.org/abs/2302.07387">arXiv</a> /
             <a href="https://github.com/amazon-science/polygon-transformer">code</a> /
            <a href="bibs/Liu_2023_CVPR.bib">bibtex</a>
          </td>
        </tr>
        <tr onmouseout="sac_stop()" onmouseover="sac_start()">
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.html">
              <papertitle> Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu</strong>,
            Alexander Levine, Chun Pong Lau, Rama Chellappa, Soheil Feizi
            <br>
            <em>CVPR</em>, 2022
            <br>
            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Segment_and_Complete_Defending_Object_Detectors_Against_Adversarial_Patch_Attacks_CVPR_2022_paper.pdf">PDF</a> /
            <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Liu_Segment_and_Complete_CVPR_2022_supplemental.pdf">Supp</a> /
            <a href="https://arxiv.org/abs/2112.04532">arXiv</a> /
            <a href="bibs/Liu_2022_CVPR.bib">bibtex</a> /
            <a href="https://github.com/joellliu/SegmentAndComplete">code</a> /
            <a href="https://aiem.jhu.edu/datasets/apricot-mask">Apricot-Mask Dataset</a>
          </td>
        </tr>
        <tr onmouseout="mat_stop()" onmouseover="mat_start()">
          <td style="padding:20px;width=100%;vertical-align:middle">
            <a href="https://ieeexplore.ieee.org/document/9798870">
              <papertitle> Mutual Adversarial Training: Learning together is better than going alone
              </papertitle>
            </a>
            <br>
            <strong>Jiang Liu</strong>,
            Chun Pong Lau,
            Hossein Souri,
            Soheil Feizi,
            Rama Chellappa
            <br>
            <em>IEEE Transactions on Information Forensics and Security (TIFS)</em>, 2022
            <br>
            <a href="https://ieeexplore.ieee.org/document/9798870">IEEE</a> /
            <a href="https://arxiv.org/abs/2112.05005">arXiv</a> /
            <a href="bibs/Liu_2022_mutual.bib">bibtex</a>
          </td>
        </tr>

              


          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:2px;"><tbody>
            <tr>
              <td>
                <h2>Professional Services</h2>
              </td>
            </tr>
          </tbody></table>
          <ul>
                <li><b>Conference Reviewer:</b></li>
                CVPR, ICCV, ECCV, ACL, ACM MM, FG, ACCV, AAAI, MICCAI
                <li><b>Journal Reviewer:</b></li>
                TPAMI, TIP, TIFS, TAI, TOPS, TMI, TCSVT, IJCV, MEDIA
              </ul><table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <tr>
                
            </tr>
          </tbody></table>
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">

                Source code credit to  <a href="https://jonbarron.info/">Dr. Jon Barron</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
